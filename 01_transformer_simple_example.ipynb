{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Transformer 기반 LLM 학습/생성 Test Code\n",
        "# 학습용 데이터 파일: The Old Man And The Sea_Korean.txt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from typing import Optional\n",
        "from transformers import AutoTokenizer  # Transformers 라이브러리 직접 임포트\n",
        "import warnings\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "matplotlib.rcParams['font.family'] = 'DejaVu Sans'  # 한글 폰트 설정\n",
        "\n",
        "\n",
        "# Transformers 경고 무시\n",
        "warnings.filterwarnings(\n",
        "    \"ignore\", message=\"Token indices sequence length is longer than\")\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"토크나이저 설정: KLUE/BERT\")\n",
        "print(\"=\"*60)\n",
        "print()\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"하드웨어 환경 확인\")\n",
        "print(\"=\"*60)\n",
        "print(f\"PyTorch 버전: {torch.__version__}\")\n",
        "print(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA 버전: {torch.version.cuda}\")\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(\n",
        "        f\"GPU 메모리: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print(\"CPU 전용 모드\")\n",
        "    device = 'cpu'\n",
        "print(f\"사용 디바이스: {device}\")\n",
        "print()\n",
        "\n",
        "# 학습용 데이터 로드\n",
        "def load_text_data(filename='The Old Man And The Sea_Korean.txt'):\n",
        "    try:\n",
        "        with open(filename, 'r', encoding='utf-8') as f:\n",
        "            sentences = [line.strip()\n",
        "                         for line in f.readlines() if line.strip()]\n",
        "        print(f\"파일에서 {len(sentences)}개의 문장 로드\")\n",
        "\n",
        "        if len(sentences) == 0:\n",
        "            print(f\"'{filename}' 파일이 비어 있음\")\n",
        "            exit(1)\n",
        "\n",
        "        return sentences\n",
        "    except FileNotFoundError:\n",
        "        print(f\"'{filename}' 파일 없음\")\n",
        "        exit(1)\n",
        "\n",
        "# 한국어 전용 토크나이저 (KLUE/BERT 기반)\n",
        "class KoreanTokenizer:\n",
        "    def __init__(self, texts):\n",
        "        print(\"KLUE/BERT 토크나이저 초기화 중...\")\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")\n",
        "\n",
        "        vocab_set = set()\n",
        "        printed_count = 0\n",
        "        total_texts = len(texts)\n",
        "\n",
        "        for i, text in enumerate(texts):\n",
        "            if i < 5 or i >= total_texts - 5:\n",
        "                if printed_count == 5:\n",
        "                    print(\"... (중간 과정 생략) ...\")\n",
        "                if i < 5 or i >= total_texts - 5:\n",
        "                    print(f\"토크나이징 진행: {i+1}/{total_texts}\")\n",
        "                    printed_count += 1\n",
        "\n",
        "            truncated_text = text[:100] if len(text) > 100 else text\n",
        "            tokens = self.tokenizer.tokenize(truncated_text)\n",
        "            vocab_set.update(tokens)\n",
        "\n",
        "        special_tokens = ['<pad>', '<sos>', '<eos>', '<unk>']\n",
        "        bert_special = ['[PAD]', '[UNK]', '[CLS]', '[SEP]', '[MASK]']\n",
        "\n",
        "        self.vocab = special_tokens + bert_special + sorted(list(vocab_set))\n",
        "        self.vocab_size = len(self.vocab)\n",
        "        self.token_to_idx = {token: i for i, token in enumerate(self.vocab)}\n",
        "        self.idx_to_token = {i: token for i, token in enumerate(self.vocab)}\n",
        "\n",
        "        print(\"=\"*60)\n",
        "        print(\"토크나이저 정보\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"토크나이저 타입: KLUE/BERT WordPiece\")\n",
        "        print(f\"어휘 크기: {self.vocab_size:,}\")\n",
        "        print(f\"토큰 예시: {self.vocab[9:19]}\")\n",
        "        print(f\"특수 토큰: {['<pad>', '<sos>', '<eos>', '<unk>']}\")\n",
        "        print()\n",
        "\n",
        "    def encode(self, text):\n",
        "        truncated_text = text[:100] if len(text) > 100 else text\n",
        "        bert_tokens = self.tokenizer.tokenize(truncated_text)\n",
        "        token_ids = [self.token_to_idx['<sos>']]\n",
        "        for token in bert_tokens:\n",
        "            token_ids.append(self.token_to_idx.get(\n",
        "                token, self.token_to_idx['<unk>']))\n",
        "        token_ids.append(self.token_to_idx['<eos>'])\n",
        "        return token_ids\n",
        "\n",
        "    def decode(self, token_ids):\n",
        "        tokens = []\n",
        "        for idx in token_ids:\n",
        "            token = self.idx_to_token[idx]\n",
        "            if token not in ['<pad>', '<sos>', '<eos>', '<unk>', '[PAD]', '[UNK]', '[CLS]', '[SEP]', '[MASK]']:\n",
        "                tokens.append(token)\n",
        "\n",
        "        return self.tokenizer.convert_tokens_to_string(tokens)\n",
        "\n",
        "# 위치 인코딩\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model: int, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
        "\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() *\n",
        "                             -(math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "        print(\"=\"*60)\n",
        "        print(\"위치 인코딩 정보\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"임베딩 차원: {d_model}\")\n",
        "        print(f\"최대 길이: {max_len}\")\n",
        "        print(f\"PE 값 범위: [{pe.min():.3f}, {pe.max():.3f}]\")\n",
        "        print(\"sin/cos 함수로 생성\")\n",
        "        print()\n",
        "\n",
        "    def forward(self, x):\n",
        "        seq_len = x.size(1)\n",
        "        return x + self.pe[:, :seq_len]\n",
        "\n",
        "# 멀티헤드 어텐션 메커니즘\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model: int, n_heads: int, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        assert d_model % n_heads == 0\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.d_k = d_model // n_heads\n",
        "\n",
        "        self.w_q = nn.Linear(d_model, d_model)\n",
        "        self.w_k = nn.Linear(d_model, d_model)\n",
        "        self.w_v = nn.Linear(d_model, d_model)\n",
        "        self.w_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.scale = math.sqrt(self.d_k)\n",
        "\n",
        "    def forward(self, x, mask: Optional[torch.Tensor] = None, verbose: bool = False):\n",
        "        batch_size, seq_len = x.size(0), x.size(1)\n",
        "\n",
        "        if verbose:\n",
        "            print(\"\\n\" + \"=\"*50)\n",
        "            print(\"Attention Mechanism Analysis\")\n",
        "            print(\"=\"*50)\n",
        "            print(f\"Input shape: {x.shape}\")\n",
        "            print(f\"Batch size: {batch_size}, Sequence length: {seq_len}\")\n",
        "            print(\n",
        "                f\"Number of heads: {self.n_heads}, Head dimension: {self.d_k}\")\n",
        "\n",
        "        Q = self.w_q(x)\n",
        "        K = self.w_k(x)\n",
        "        V = self.w_v(x)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Q, K, V shape: {Q.shape}\")\n",
        "            print(\n",
        "                f\"Q sample (first token, first 5 values): {Q[0, 0, :5].detach()}\")\n",
        "\n",
        "        Q = Q.view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
        "        K = K.view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
        "        V = V.view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Multi-head Q, K, V shape: {Q.shape}\")\n",
        "            print(f\"First head Q sample: {Q[0, 0, 0, :5].detach()}\")\n",
        "\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / self.scale\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Attention scores shape: {scores.shape}\")\n",
        "            print(f\"Scaling factor: {self.scale:.3f}\")\n",
        "            print(f\"Attention scores sample (first head, 3x3):\")\n",
        "            print(f\"{scores[0, 0, :3, :3].detach()}\")\n",
        "\n",
        "        if mask is not None:\n",
        "            if verbose:\n",
        "                print(f\"Causal mask shape: {mask.shape}\")\n",
        "                print(f\"Causal mask sample (3x3):\")\n",
        "                print(f\"{mask[0, 0, :3, :3]}\")\n",
        "\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"Masked attention scores (3x3):\")\n",
        "                print(f\"{scores[0, 0, :3, :3].detach()}\")\n",
        "\n",
        "        attn_weights = F.softmax(scores, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Attention weights shape: {attn_weights.shape}\")\n",
        "            print(f\"Attention weights sample (first head, 3x3):\")\n",
        "            print(f\"{attn_weights[0, 0, :3, :3].detach()}\")\n",
        "            print(\n",
        "                f\"Row sums (should be 1.0): {attn_weights[0, 0, :3].sum(dim=-1).detach()}\")\n",
        "\n",
        "        output = torch.matmul(attn_weights, V)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Weighted value output shape: {output.shape}\")\n",
        "            print(f\"First head output sample: {output[0, 0, 0, :5].detach()}\")\n",
        "\n",
        "        output = output.transpose(1, 2).contiguous().view(\n",
        "            batch_size, seq_len, self.d_model)\n",
        "        output = self.w_o(output)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Final attention output shape: {output.shape}\")\n",
        "            print(\"=\"*50)\n",
        "\n",
        "        return output\n",
        "\n",
        "# 피드포워드 신경망\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model: int, d_ff: int, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(d_model, d_ff)\n",
        "        self.linear2 = nn.Linear(d_ff, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(self, x, verbose: bool = False):\n",
        "        if verbose:\n",
        "            print(\"\\n\" + \"=\"*40)\n",
        "            print(\"Feed Forward Network\")\n",
        "            print(\"=\"*40)\n",
        "            print(f\"Input shape: {x.shape}\")\n",
        "\n",
        "        x = self.linear1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear2(x)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Output shape: {x.shape}\")\n",
        "            print(\"=\"*40)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Decoder Block\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, d_model: int, n_heads: int, d_ff: int, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.attention = MultiHeadAttention(d_model, n_heads, dropout)\n",
        "        self.feed_forward = FeedForward(d_model, d_ff, dropout)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask: Optional[torch.Tensor] = None, verbose: bool = False):\n",
        "        attn_output = self.attention(x, mask, verbose)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "\n",
        "        ff_output = self.feed_forward(x, verbose)\n",
        "        x = self.norm2(x + self.dropout(ff_output))\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Decoder block final output: {x.shape}\")\n",
        "            print(\"=\"*50)\n",
        "\n",
        "        return x\n",
        "\n",
        "# GPT Style Decoder-Only Transformer\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, vocab_size: int, d_model: int, n_heads: int,\n",
        "                 n_layers: int, d_ff: int, max_seq_len: int, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.d_model = d_model\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.n_heads = n_heads\n",
        "        self.n_layers = n_layers\n",
        "        self.d_ff = d_ff\n",
        "\n",
        "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_encoding = PositionalEncoding(d_model, max_seq_len)\n",
        "\n",
        "        self.decoder_blocks = nn.ModuleList([\n",
        "            DecoderBlock(d_model, n_heads, d_ff, dropout)\n",
        "            for _ in range(n_layers)\n",
        "        ])\n",
        "\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "        self.output_projection = nn.Linear(d_model, vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        print(\"=\"*60)\n",
        "        print(\"모델 구조\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"모델 타입: GPT (Decoder-Only Transformer)\")\n",
        "        print(f\"어휘 크기: {vocab_size:,}\")\n",
        "        print(f\"임베딩 차원: {d_model}\")\n",
        "        print(f\"어텐션 헤드: {n_heads}\")\n",
        "        print(f\"디코더 층: {n_layers}\")\n",
        "        print(f\"FFN 차원: {d_ff}\")\n",
        "        print(f\"최대 시퀀스 길이: {max_seq_len}\")\n",
        "        print(f\"드롭아웃: {dropout}\")\n",
        "\n",
        "        total_params = sum(p.numel() for p in self.parameters())\n",
        "        print(f\"총 파라미터: {total_params:,}\")\n",
        "        print()\n",
        "\n",
        "    # 인과 마스크 생성 (자기회귀 모델용)\n",
        "    def create_causal_mask(self, seq_len: int, device: torch.device):\n",
        "        mask = torch.tril(torch.ones(seq_len, seq_len, device=device))\n",
        "        return mask.unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "    def forward(self, x, verbose: bool = False):\n",
        "        batch_size, seq_len = x.size()\n",
        "\n",
        "        if verbose:\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"Model Forward Pass Analysis\")\n",
        "            print(\"=\"*60)\n",
        "            print(f\"Input shape: {x.shape}\")\n",
        "            print(f\"Input token IDs (first sample): {x[0].detach()}\")\n",
        "            print(f\"Batch size: {batch_size}, Sequence length: {seq_len}\")\n",
        "\n",
        "        x = self.token_embedding(x)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"\\n[1. Token Embedding]\")\n",
        "            print(f\"Embedding shape: {x.shape}\")\n",
        "            print(\n",
        "                f\"First token embedding (first 5 values): {x[0, 0, :5].detach()}\")\n",
        "\n",
        "        x = x * math.sqrt(self.d_model)\n",
        "\n",
        "        if verbose:\n",
        "            print(\n",
        "                f\"Scaling factor: √{self.d_model} = {math.sqrt(self.d_model):.3f}\")\n",
        "            print(f\"Scaled embedding (first 5 values): {x[0, 0, :5].detach()}\")\n",
        "\n",
        "        x = self.pos_encoding(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"\\n[2. Positional Encoding]\")\n",
        "            print(f\"After positional encoding shape: {x.shape}\")\n",
        "            print(\n",
        "                f\"After positional encoding (first 5 values): {x[0, 0, :5].detach()}\")\n",
        "\n",
        "        causal_mask = self.create_causal_mask(seq_len, x.device)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"\\n[3. Causal Mask]\")\n",
        "            print(f\"Causal mask shape: {causal_mask.shape}\")\n",
        "            print(f\"Causal mask sample (lower triangular matrix):\")\n",
        "            mask_sample = causal_mask[0, 0, :min(5, seq_len), :min(5, seq_len)]\n",
        "            print(mask_sample)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"\\n[4. Decoder Blocks Processing]\")\n",
        "            print(\n",
        "                f\"Total {len(self.decoder_blocks)} decoder blocks to process\")\n",
        "\n",
        "        for i, block in enumerate(self.decoder_blocks):\n",
        "            if verbose:\n",
        "                print(f\"\\n--- Decoder Block {i+1} ---\")\n",
        "                x_before = x.clone().detach()\n",
        "\n",
        "            x = block(x, causal_mask, verbose and i == 0)\n",
        "\n",
        "            if verbose:\n",
        "                residual_effect = (x.detach() - x_before).abs().mean()\n",
        "                print(\n",
        "                    f\"Block {i+1} residual effect (change amount): {residual_effect:.4f}\")\n",
        "\n",
        "        x = self.norm(x)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"\\n[5. Final Output]\")\n",
        "            print(f\"After layer norm (first 5 values): {x[0, 0, :5].detach()}\")\n",
        "\n",
        "        logits = self.output_projection(x)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Final logits shape: {logits.shape}\")\n",
        "            print(\n",
        "                f\"Last token logits range: [{logits[0, -1].min().item():.3f}, {logits[0, -1].max().item():.3f}]\")\n",
        "            print(\"=\"*60)\n",
        "\n",
        "        return logits\n",
        "\n",
        "# 배치 데이터 생성\n",
        "def create_batches(tokenizer, texts, max_seq_len, batch_size):\n",
        "    all_tokens = []\n",
        "\n",
        "    print(f\"배치 생성 중... (최대 시퀀스 길이: {max_seq_len})\")\n",
        "\n",
        "    total_texts = len(texts)\n",
        "    printed_count = 0\n",
        "\n",
        "    for i, text in enumerate(texts):\n",
        "        if i < 5 or i >= total_texts - 5:\n",
        "            if printed_count == 5:\n",
        "                print(\"... (중간 과정 생략) ...\")\n",
        "            print(f\"처리된 텍스트: {i+1}/{total_texts}, 생성된 시퀀스: {len(all_tokens)}\")\n",
        "            printed_count += 1\n",
        "\n",
        "        tokens = tokenizer.encode(text)\n",
        "\n",
        "        if len(tokens) > max_seq_len:\n",
        "            for start in range(0, len(tokens), max_seq_len - 2):\n",
        "                chunk = tokens[start:start + max_seq_len - 2]\n",
        "                if len(chunk) >= 10:\n",
        "                    chunk = [tokenizer.token_to_idx['<sos>']] + \\\n",
        "                        chunk[1:-1] + [tokenizer.token_to_idx['<eos>']]\n",
        "\n",
        "                    while len(chunk) < max_seq_len:\n",
        "                        chunk.append(tokenizer.token_to_idx['<pad>'])\n",
        "\n",
        "                    all_tokens.append(chunk)\n",
        "        else:\n",
        "            while len(tokens) < max_seq_len:\n",
        "                tokens.append(tokenizer.token_to_idx['<pad>'])\n",
        "            all_tokens.append(tokens)\n",
        "\n",
        "    if len(all_tokens) == 0:\n",
        "        print(\"ERROR: 처리된 토큰 시퀀스가 없음!\")\n",
        "        return []\n",
        "\n",
        "    print(f\"총 {len(all_tokens)}개의 시퀀스가 생성...\")\n",
        "\n",
        "    data = torch.tensor(all_tokens, dtype=torch.long)\n",
        "\n",
        "    batches = []\n",
        "    for i in range(0, len(data), batch_size):\n",
        "        batch = data[i:i+batch_size]\n",
        "        batches.append(batch)\n",
        "\n",
        "    print(f\"총 {len(batches)}개의 배치 생성...\")\n",
        "    return batches\n",
        "\n",
        "# 모델 학습\n",
        "def train_model(model, batches, tokenizer, epochs, device, lr=3e-4):\n",
        "    if len(batches) == 0:\n",
        "        print(\"ERROR: 학습할 배치가 없음!!\")\n",
        "        print(\"- 텍스트 파일의 문장이 너무 적거나\")\n",
        "        print(\"- 배치 크기가 너무 크거나\")\n",
        "        print(\"- 시퀀스 길이가 너무 길 수 있습니다.\")\n",
        "        return []\n",
        "\n",
        "    model.train()\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(), lr=lr, weight_decay=0.01, betas=(0.9, 0.95))\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "        optimizer, T_0=epochs//2)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(\n",
        "        ignore_index=tokenizer.token_to_idx['<pad>'])\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(\"모델 학습 시작\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"학습 배치 수: {len(batches)}\")\n",
        "    print(f\"초기 학습률: {lr}\")\n",
        "\n",
        "    losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        num_batches = 0\n",
        "\n",
        "        for batch_idx, batch in enumerate(batches):\n",
        "            batch = batch.to(device, non_blocking=True)\n",
        "\n",
        "            inputs = batch[:, :-1]\n",
        "            targets = batch[:, 1:]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            logits = model(inputs, verbose=(epoch == 0 and batch_idx == 0))\n",
        "\n",
        "            loss = criterion(\n",
        "                logits.reshape(-1, logits.size(-1)), targets.reshape(-1))\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "            if num_batches >= min(20, len(batches)):\n",
        "                break\n",
        "\n",
        "        if num_batches > 0:\n",
        "            avg_loss = total_loss / num_batches\n",
        "            losses.append(avg_loss)\n",
        "            current_lr = optimizer.param_groups[0]['lr']\n",
        "            print(\n",
        "                f\"에포크 {epoch+1:2d}/{epochs}, 손실: {avg_loss:.4f}, 학습률: {current_lr:.6f}\")\n",
        "        else:\n",
        "            print(f\"에포크 {epoch+1:2d}/{epochs}, 배치 없음 - 학습 중단!!\")\n",
        "            break\n",
        "\n",
        "    return losses\n",
        "\n",
        "# 모델 저장\n",
        "def save_model(model, tokenizer, filepath):\n",
        "    checkpoint = {\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'vocab_size': tokenizer.vocab_size,\n",
        "        'd_model': model.d_model,\n",
        "        'n_heads': model.n_heads,\n",
        "        'n_layers': model.n_layers,\n",
        "        'd_ff': model.d_ff,\n",
        "        'max_seq_len': model.max_seq_len,\n",
        "        'vocab': tokenizer.vocab,\n",
        "        'token_to_idx': tokenizer.token_to_idx,\n",
        "        'idx_to_token': tokenizer.idx_to_token,\n",
        "    }\n",
        "    torch.save(checkpoint, filepath)\n",
        "    print(f\"모델이 '{filepath}'에 저장되었습니다.\")\n",
        "\n",
        "def plot_training_loss(losses):\n",
        "    if not losses:\n",
        "        print(\"손실 데이터가 없어 그래프를 그릴 수 없습니다.\")\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    epochs = range(1, len(losses) + 1)\n",
        "\n",
        "    # 손실 그래프\n",
        "    plt.plot(epochs, losses, 'b-', linewidth=2, marker='o', markersize=4)\n",
        "    plt.title('Training Loss Over Epochs', fontsize=16, fontweight='bold')\n",
        "    plt.xlabel('Epoch', fontsize=12)\n",
        "    plt.ylabel('Loss', fontsize=12)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 학습 실행 함수\n",
        "def run_training():\n",
        "    # 하이퍼파라미터 설정\n",
        "\n",
        "    MAX_SEQ_LEN = 256     # 시퀀스 길이\n",
        "    BATCH_SIZE = 3       # 배치 크기\n",
        "    D_MODEL = 256        # 모델 크기\n",
        "    N_HEADS = 16          # 헤드 수\n",
        "    N_LAYERS = 12         # 레이어 수\n",
        "    D_FF = 256           # FFN 크기\n",
        "    EPOCHS = 60           # 에포크\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(\"모델 학습 모드\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"시퀀스 길이: {MAX_SEQ_LEN}\")\n",
        "    print(f\"배치 크기: {BATCH_SIZE}\")\n",
        "    print(f\"모델 크기: {D_MODEL}\")\n",
        "    print()\n",
        "\n",
        "    # 데이터 로드 및 토크나이저 생성\n",
        "    texts = load_text_data()\n",
        "    # 단일 토크나이저를 직접 생성합니다.\n",
        "    tokenizer = KoreanTokenizer(texts)\n",
        "\n",
        "    # 모델 생성\n",
        "    model = GPTModel(\n",
        "        vocab_size=tokenizer.vocab_size,\n",
        "        d_model=D_MODEL,\n",
        "        n_heads=N_HEADS,\n",
        "        n_layers=N_LAYERS,\n",
        "        d_ff=D_FF,\n",
        "        max_seq_len=MAX_SEQ_LEN\n",
        "    ).to(device)\n",
        "\n",
        "    # 배치 데이터 생성\n",
        "    batches = create_batches(tokenizer, texts, MAX_SEQ_LEN, BATCH_SIZE)\n",
        "\n",
        "    if len(batches) == 0:\n",
        "        print(\"ERROR: 배치 생성에 실패!!\")\n",
        "        print(\"1. 텍스트 파일에 충분한 내용이 있는지?\")\n",
        "        print(\"2. 텍스트 파일 인코딩이 UTF-8인지?\")\n",
        "        return False\n",
        "\n",
        "    print(f\"총 배치 수: {len(batches)}\")\n",
        "\n",
        "    # 모델 학습\n",
        "    losses = train_model(model, batches, tokenizer, EPOCHS, device)\n",
        "\n",
        "    # 모델 저장\n",
        "    if losses:\n",
        "        save_model(model, tokenizer, 'gpt_model.pth')\n",
        "\n",
        "        plot_training_loss(losses)\n",
        "\n",
        "        print(\"학습 완료!\")\n",
        "        return True\n",
        "    else:\n",
        "        print(\"학습 실패 - 모델 저장 실패!!\")\n",
        "        return False\n",
        "\n",
        "\n",
        "# 학습 실행\n",
        "print(\"모델 학습\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "success = run_training()\n",
        "\n",
        "if success:\n",
        "    print(\"\\n학습 성공...\")\n",
        "else:\n",
        "    print(\"\\n학습 실패!!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U6vqLoBunO7Z",
        "outputId": "c39dda99-36b4-4730-e791-615084950372"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "토크나이저 설정: KLUE/BERT\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "하드웨어 환경 확인\n",
            "============================================================\n",
            "PyTorch 버전: 2.8.0+cu126\n",
            "CUDA 사용 가능: False\n",
            "CPU 전용 모드\n",
            "사용 디바이스: cpu\n",
            "\n",
            "모델 학습\n",
            "============================================================\n",
            "============================================================\n",
            "모델 학습 모드\n",
            "============================================================\n",
            "시퀀스 길이: 256\n",
            "배치 크기: 3\n",
            "모델 크기: 256\n",
            "\n",
            "파일에서 1개의 문장 로드\n",
            "KLUE/BERT 토크나이저 초기화 중...\n",
            "토크나이징 진행: 1/1\n",
            "============================================================\n",
            "토크나이저 정보\n",
            "============================================================\n",
            "토크나이저 타입: KLUE/BERT WordPiece\n",
            "어휘 크기: 54\n",
            "토큰 예시: ['##고', '##곤', '##는', '##는데', '##다', '##를', '##만', '##배', '##세', '##송']\n",
            "특수 토큰: ['<pad>', '<sos>', '<eos>', '<unk>']\n",
            "\n",
            "============================================================\n",
            "위치 인코딩 정보\n",
            "============================================================\n",
            "임베딩 차원: 256\n",
            "최대 길이: 256\n",
            "PE 값 범위: [-1.000, 1.000]\n",
            "sin/cos 함수로 생성\n",
            "\n",
            "============================================================\n",
            "모델 구조\n",
            "============================================================\n",
            "모델 타입: GPT (Decoder-Only Transformer)\n",
            "어휘 크기: 54\n",
            "임베딩 차원: 256\n",
            "어텐션 헤드: 16\n",
            "디코더 층: 12\n",
            "FFN 차원: 256\n",
            "최대 시퀀스 길이: 256\n",
            "드롭아웃: 0.1\n",
            "총 파라미터: 4,777,526\n",
            "\n",
            "배치 생성 중... (최대 시퀀스 길이: 256)\n",
            "처리된 텍스트: 1/1, 생성된 시퀀스: 0\n",
            "총 1개의 시퀀스가 생성...\n",
            "총 1개의 배치 생성...\n",
            "총 배치 수: 1\n",
            "============================================================\n",
            "모델 학습 시작\n",
            "============================================================\n",
            "학습 배치 수: 1\n",
            "초기 학습률: 0.0003\n",
            "\n",
            "============================================================\n",
            "Model Forward Pass Analysis\n",
            "============================================================\n",
            "Input shape: torch.Size([1, 255])\n",
            "Input token IDs (first sample): tensor([ 1, 34, 11, 41, 40, 20, 45, 16, 14, 48, 33, 26, 14, 49, 11, 37, 24, 19,\n",
            "        13, 30, 38, 23, 53, 16, 14, 48, 35, 10, 51, 12, 29, 33, 50, 39, 36, 27,\n",
            "        42,  9, 52, 18, 17, 22, 15, 44, 46, 43, 32, 25, 28, 21, 13, 30, 47, 31,\n",
            "         2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0])\n",
            "Batch size: 1, Sequence length: 255\n",
            "\n",
            "[1. Token Embedding]\n",
            "Embedding shape: torch.Size([1, 255, 256])\n",
            "First token embedding (first 5 values): tensor([ 0.5850, -1.6118,  0.5724,  0.0382, -1.0619])\n",
            "Scaling factor: √256 = 16.000\n",
            "Scaled embedding (first 5 values): tensor([  9.3603, -25.7892,   9.1580,   0.6106, -16.9908])\n",
            "\n",
            "[2. Positional Encoding]\n",
            "After positional encoding shape: torch.Size([1, 255, 256])\n",
            "After positional encoding (first 5 values): tensor([  0.0000, -27.5436,  10.1756,   1.7895, -18.8787])\n",
            "\n",
            "[3. Causal Mask]\n",
            "Causal mask shape: torch.Size([1, 1, 255, 255])\n",
            "Causal mask sample (lower triangular matrix):\n",
            "tensor([[1., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 0.],\n",
            "        [1., 1., 1., 1., 1.]])\n",
            "\n",
            "[4. Decoder Blocks Processing]\n",
            "Total 12 decoder blocks to process\n",
            "\n",
            "--- Decoder Block 1 ---\n",
            "\n",
            "==================================================\n",
            "Attention Mechanism Analysis\n",
            "==================================================\n",
            "Input shape: torch.Size([1, 255, 256])\n",
            "Batch size: 1, Sequence length: 255\n",
            "Number of heads: 16, Head dimension: 16\n",
            "Q, K, V shape: torch.Size([1, 255, 256])\n",
            "Q sample (first token, first 5 values): tensor([ 13.3607,   9.1797,   6.1008, -20.4105, -17.5464])\n",
            "Multi-head Q, K, V shape: torch.Size([1, 16, 255, 16])\n",
            "First head Q sample: tensor([ 13.3607,   9.1797,   6.1008, -20.4105, -17.5464])\n",
            "Attention scores shape: torch.Size([1, 16, 255, 255])\n",
            "Scaling factor: 4.000\n",
            "Attention scores sample (first head, 3x3):\n",
            "tensor([[ -50.0499,    9.1198, -199.9080],\n",
            "        [  67.5854,  -65.0492,   77.8511],\n",
            "        [  52.7925,   43.9066,  211.6759]])\n",
            "Causal mask shape: torch.Size([1, 1, 255, 255])\n",
            "Causal mask sample (3x3):\n",
            "tensor([[1., 0., 0.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 1., 1.]])\n",
            "Masked attention scores (3x3):\n",
            "tensor([[-5.0050e+01, -1.0000e+09, -1.0000e+09],\n",
            "        [ 6.7585e+01, -6.5049e+01, -1.0000e+09],\n",
            "        [ 5.2792e+01,  4.3907e+01,  2.1168e+02]])\n",
            "Attention weights shape: torch.Size([1, 16, 255, 255])\n",
            "Attention weights sample (first head, 3x3):\n",
            "tensor([[1.1111, 0.0000, 0.0000],\n",
            "        [1.1111, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 1.1111]])\n",
            "Row sums (should be 1.0): tensor([1.1111, 1.1111, 1.1111])\n",
            "Weighted value output shape: torch.Size([1, 16, 255, 16])\n",
            "First head output sample: tensor([-10.8530,  -6.8573,  -2.2811,  18.1502,  12.5342])\n",
            "Final attention output shape: torch.Size([1, 255, 256])\n",
            "==================================================\n",
            "\n",
            "========================================\n",
            "Feed Forward Network\n",
            "========================================\n",
            "Input shape: torch.Size([1, 255, 256])\n",
            "Output shape: torch.Size([1, 255, 256])\n",
            "========================================\n",
            "Decoder block final output: torch.Size([1, 255, 256])\n",
            "==================================================\n",
            "Block 1 residual effect (change amount): 11.8598\n",
            "\n",
            "--- Decoder Block 2 ---\n",
            "Block 2 residual effect (change amount): 0.2482\n",
            "\n",
            "--- Decoder Block 3 ---\n",
            "Block 3 residual effect (change amount): 0.2550\n",
            "\n",
            "--- Decoder Block 4 ---\n",
            "Block 4 residual effect (change amount): 0.2685\n",
            "\n",
            "--- Decoder Block 5 ---\n",
            "Block 5 residual effect (change amount): 0.2512\n",
            "\n",
            "--- Decoder Block 6 ---\n",
            "Block 6 residual effect (change amount): 0.2801\n",
            "\n",
            "--- Decoder Block 7 ---\n",
            "Block 7 residual effect (change amount): 0.2587\n",
            "\n",
            "--- Decoder Block 8 ---\n",
            "Block 8 residual effect (change amount): 0.2638\n",
            "\n",
            "--- Decoder Block 9 ---\n",
            "Block 9 residual effect (change amount): 0.2602\n",
            "\n",
            "--- Decoder Block 10 ---\n",
            "Block 10 residual effect (change amount): 0.2934\n",
            "\n",
            "--- Decoder Block 11 ---\n",
            "Block 11 residual effect (change amount): 0.2586\n",
            "\n",
            "--- Decoder Block 12 ---\n",
            "Block 12 residual effect (change amount): 0.2585\n",
            "\n",
            "[5. Final Output]\n",
            "After layer norm (first 5 values): tensor([-0.0334,  0.7028,  0.1103,  0.6486, -0.3972])\n",
            "Final logits shape: torch.Size([1, 255, 54])\n",
            "Last token logits range: [-1.327, 1.420]\n",
            "============================================================\n",
            "에포크  1/60, 손실: 4.0390, 학습률: 0.000299\n",
            "에포크  2/60, 손실: 3.6004, 학습률: 0.000297\n",
            "에포크  3/60, 손실: 3.2712, 학습률: 0.000293\n",
            "에포크  4/60, 손실: 2.9333, 학습률: 0.000287\n",
            "에포크  5/60, 손실: 2.5538, 학습률: 0.000280\n",
            "에포크  6/60, 손실: 2.2591, 학습률: 0.000271\n",
            "에포크  7/60, 손실: 1.9369, 학습률: 0.000261\n",
            "에포크  8/60, 손실: 1.7747, 학습률: 0.000250\n",
            "에포크  9/60, 손실: 1.4340, 학습률: 0.000238\n",
            "에포크 10/60, 손실: 1.2549, 학습률: 0.000225\n",
            "에포크 11/60, 손실: 1.1283, 학습률: 0.000211\n",
            "에포크 12/60, 손실: 0.9841, 학습률: 0.000196\n",
            "에포크 13/60, 손실: 0.8898, 학습률: 0.000181\n",
            "에포크 14/60, 손실: 0.7802, 학습률: 0.000166\n",
            "에포크 15/60, 손실: 0.7084, 학습률: 0.000150\n",
            "에포크 16/60, 손실: 0.6180, 학습률: 0.000134\n",
            "에포크 17/60, 손실: 0.5709, 학습률: 0.000119\n",
            "에포크 18/60, 손실: 0.5370, 학습률: 0.000104\n",
            "에포크 19/60, 손실: 0.5267, 학습률: 0.000089\n",
            "에포크 20/60, 손실: 0.4847, 학습률: 0.000075\n",
            "에포크 21/60, 손실: 0.4648, 학습률: 0.000062\n",
            "에포크 22/60, 손실: 0.4061, 학습률: 0.000050\n",
            "에포크 23/60, 손실: 0.4157, 학습률: 0.000039\n",
            "에포크 24/60, 손실: 0.3588, 학습률: 0.000029\n",
            "에포크 25/60, 손실: 0.3835, 학습률: 0.000020\n",
            "에포크 26/60, 손실: 0.3890, 학습률: 0.000013\n",
            "에포크 27/60, 손실: 0.3729, 학습률: 0.000007\n",
            "에포크 28/60, 손실: 0.3712, 학습률: 0.000003\n",
            "에포크 29/60, 손실: 0.3903, 학습률: 0.000001\n",
            "에포크 30/60, 손실: 0.3559, 학습률: 0.000300\n",
            "에포크 31/60, 손실: 0.3474, 학습률: 0.000299\n",
            "에포크 32/60, 손실: 0.2976, 학습률: 0.000297\n",
            "에포크 33/60, 손실: 0.2910, 학습률: 0.000293\n",
            "에포크 34/60, 손실: 0.2407, 학습률: 0.000287\n",
            "에포크 35/60, 손실: 0.2026, 학습률: 0.000280\n",
            "에포크 36/60, 손실: 0.1698, 학습률: 0.000271\n",
            "에포크 37/60, 손실: 0.1502, 학습률: 0.000261\n",
            "에포크 38/60, 손실: 0.1518, 학습률: 0.000250\n",
            "에포크 39/60, 손실: 0.1184, 학습률: 0.000238\n",
            "에포크 40/60, 손실: 0.1072, 학습률: 0.000225\n",
            "에포크 41/60, 손실: 0.1058, 학습률: 0.000211\n",
            "에포크 42/60, 손실: 0.0958, 학습률: 0.000196\n",
            "에포크 43/60, 손실: 0.0823, 학습률: 0.000181\n",
            "에포크 44/60, 손실: 0.0684, 학습률: 0.000166\n",
            "에포크 45/60, 손실: 0.0680, 학습률: 0.000150\n",
            "에포크 46/60, 손실: 0.0648, 학습률: 0.000134\n",
            "에포크 47/60, 손실: 0.0633, 학습률: 0.000119\n",
            "에포크 48/60, 손실: 0.0567, 학습률: 0.000104\n",
            "에포크 49/60, 손실: 0.0525, 학습률: 0.000089\n",
            "에포크 50/60, 손실: 0.0518, 학습률: 0.000075\n",
            "에포크 51/60, 손실: 0.0429, 학습률: 0.000062\n",
            "에포크 52/60, 손실: 0.0436, 학습률: 0.000050\n",
            "에포크 53/60, 손실: 0.0531, 학습률: 0.000039\n",
            "에포크 54/60, 손실: 0.0434, 학습률: 0.000029\n",
            "에포크 55/60, 손실: 0.0427, 학습률: 0.000020\n",
            "에포크 56/60, 손실: 0.0421, 학습률: 0.000013\n",
            "에포크 57/60, 손실: 0.0397, 학습률: 0.000007\n",
            "에포크 58/60, 손실: 0.0451, 학습률: 0.000003\n",
            "에포크 59/60, 손실: 0.0409, 학습률: 0.000001\n",
            "에포크 60/60, 손실: 0.0431, 학습률: 0.000300\n",
            "모델이 'gpt_model.pth'에 저장되었습니다.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 완료!\n",
            "\n",
            "학습 성공...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트 생성 부분 (모델 로드 및 생성)\n",
        "\n",
        "# 로드된 토크나이저 클래스\n",
        "class LoadedTokenizer:\n",
        "    def __init__(self, vocab, token_to_idx, idx_to_token):\n",
        "        self.vocab = vocab\n",
        "        self.vocab_size = len(vocab)\n",
        "        self.token_to_idx = token_to_idx\n",
        "        self.idx_to_token = idx_to_token\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")\n",
        "\n",
        "    def encode(self, text):\n",
        "        # KLUE/BERT 인코딩\n",
        "        truncated_text = text[:100] if len(text) > 100 else text\n",
        "        bert_tokens = self.tokenizer.tokenize(truncated_text)\n",
        "        token_ids = [self.token_to_idx['<sos>']]\n",
        "        for token in bert_tokens:\n",
        "            token_ids.append(self.token_to_idx.get(\n",
        "                token, self.token_to_idx['<unk>']))\n",
        "        token_ids.append(self.token_to_idx['<eos>'])\n",
        "        return token_ids\n",
        "\n",
        "    def decode(self, token_ids):\n",
        "        # KLUE/BERT 디코딩\n",
        "        tokens = []\n",
        "        for idx in token_ids:\n",
        "            token = self.idx_to_token[idx]\n",
        "            if token not in ['<pad>', '<sos>', '<eos>', '<unk>', '[PAD]', '[UNK]', '[CLS]', '[SEP]', '[MASK]']:\n",
        "                tokens.append(token)\n",
        "\n",
        "        return self.tokenizer.convert_tokens_to_string(tokens)\n",
        "\n",
        "# 모델 로드\n",
        "def load_model(filepath, device):\n",
        "    try:\n",
        "        checkpoint = torch.load(filepath, map_location=device)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"모델 파일 '{filepath}'을 찾기 실패!!\")\n",
        "        return None, None\n",
        "\n",
        "    # 토크나이저 복원 (use_bert, tokenizer_type 없이)\n",
        "    tokenizer = LoadedTokenizer(\n",
        "        checkpoint['vocab'],\n",
        "        checkpoint['token_to_idx'],\n",
        "        checkpoint['idx_to_token']\n",
        "    )\n",
        "\n",
        "    # 모델 생성 및 가중치 로드\n",
        "    model = GPTModel(\n",
        "        vocab_size=checkpoint['vocab_size'],\n",
        "        d_model=checkpoint['d_model'],\n",
        "        n_heads=checkpoint['n_heads'],\n",
        "        n_layers=checkpoint['n_layers'],\n",
        "        d_ff=checkpoint['d_ff'],\n",
        "        max_seq_len=checkpoint['max_seq_len']\n",
        "    ).to(device)\n",
        "\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.eval()\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(\"모델 로드 완료\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"모델 타입: Decoder-Only Transformer\")\n",
        "    print(f\"어휘 크기: {checkpoint['vocab_size']:,}\")\n",
        "    print(f\"임베딩 차원: {checkpoint['d_model']}\")\n",
        "    print(f\"어텐션 헤드: {checkpoint['n_heads']}\")\n",
        "    print(f\"디코더 층: {checkpoint['n_layers']}\")\n",
        "    print(f\"최대 시퀀스 길이: {checkpoint['max_seq_len']}\")\n",
        "    # 토크나이저 정보 고정\n",
        "    print(f\"토크나이저: KLUE/BERT\")\n",
        "    print()\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "# 텍스트 생성 (Top 5 후보 표시)\n",
        "def generate_text_with_candidates(model, tokenizer, prompt, max_length, device, temperature=1.0, verbose=False):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        tokens = tokenizer.encode(prompt)\n",
        "        if verbose:\n",
        "            print(f\"Input text: '{prompt}' (Temperature: {temperature})\")\n",
        "            print(f\"Tokenized result: {tokens}\")\n",
        "            if len(tokens) > 0:\n",
        "                decoded_tokens = [\n",
        "                    f\"{token_id}:{tokenizer.idx_to_token[token_id]}\" for token_id in tokens]\n",
        "                print(f\"Token details: {decoded_tokens}\")\n",
        "\n",
        "        generated_tokens = tokens.copy()\n",
        "        all_candidates = []\n",
        "\n",
        "        for i in range(max_length):\n",
        "            if len(generated_tokens) >= model.max_seq_len:\n",
        "                if verbose:\n",
        "                    print(\n",
        "                        f\"Maximum sequence length ({model.max_seq_len}) reached!\")\n",
        "                break\n",
        "\n",
        "            input_tokens = generated_tokens[-model.max_seq_len:]\n",
        "            current_input = torch.tensor([input_tokens], device=device)\n",
        "            logits = model(current_input, verbose=(verbose and i == 0))\n",
        "            next_token_logits = logits[0, -1]\n",
        "\n",
        "            if temperature == 0.0:\n",
        "                next_token = torch.argmax(next_token_logits).item()\n",
        "                probs = F.softmax(next_token_logits, dim=-1)\n",
        "            else:\n",
        "                scaled_logits = next_token_logits / temperature\n",
        "                probs = F.softmax(scaled_logits, dim=-1)\n",
        "                next_token = torch.multinomial(probs, 1).item()\n",
        "\n",
        "            top_probs, top_indices = torch.topk(probs, 5)\n",
        "            step_candidates = []\n",
        "            for j, (prob, idx) in enumerate(zip(top_probs, top_indices)):\n",
        "                token = tokenizer.idx_to_token[idx.item()]\n",
        "                step_candidates.append({\n",
        "                    'rank': j + 1, 'token': token, 'probability': prob.item(),\n",
        "                    'selected': idx.item() == next_token\n",
        "                })\n",
        "            all_candidates.append(step_candidates)\n",
        "\n",
        "            if verbose and i < 5:\n",
        "                current_text = tokenizer.decode(generated_tokens)\n",
        "                print(f\"\\n--- Generation Step {i+1} ---\")\n",
        "                print(f\"Current text: '{current_text}'\")\n",
        "                print(f\"Next token candidates:\")\n",
        "\n",
        "                selected_in_top5 = any(c['selected'] for c in step_candidates)\n",
        "                for candidate in step_candidates:\n",
        "                    selected_mark = \" ★\" if candidate['selected'] else \"\"\n",
        "                    token_idx = tokenizer.token_to_idx.get(\n",
        "                        candidate['token'], tokenizer.token_to_idx['<unk>'])\n",
        "                    preview_text = tokenizer.decode(\n",
        "                        generated_tokens + [token_idx])\n",
        "                    print(\n",
        "                        f\"  {candidate['rank']}. '{candidate['token']}' → '{preview_text}' (prob: {candidate['probability']:.4f}){selected_mark}\")\n",
        "                if not selected_in_top5:\n",
        "                    selected_token = tokenizer.idx_to_token[next_token]\n",
        "                    print(\n",
        "                        f\"  Actually selected token '{selected_token}' not in top 5\")\n",
        "\n",
        "            eos_token_id = tokenizer.token_to_idx.get('<eos>', -1)\n",
        "            if next_token == eos_token_id:\n",
        "                if verbose:\n",
        "                    print(f\"Encountered <eos> token, stopping generation...\")\n",
        "                break\n",
        "            generated_tokens.append(next_token)\n",
        "\n",
        "        generated_text = tokenizer.decode(generated_tokens)\n",
        "        return generated_text, all_candidates\n",
        "\n",
        "# 텍스트 생성\n",
        "def run_generation(input_text, max_length=20):\n",
        "    model, tokenizer = load_model('gpt_model.pth', device)\n",
        "    if model is None:\n",
        "        return\n",
        "\n",
        "    print(f\"입력 텍스트: '{input_text}'\")\n",
        "    print(f\"생성 길이: {max_length}\\n\")\n",
        "    temperatures = [0.3, 0.7, 1.0, 1.3, 1.7]\n",
        "    temp_descriptions = [\n",
        "        \"가장 확률 높은 토큰 선택\", \"안정적인 토큰 생성\",\n",
        "        \"균형잡힌 토큰 생성\", \"창의적 (다양한 표현)\", \"매우 창의적 (실험적 생성)\"\n",
        "    ]\n",
        "    for i, (temp, desc) in enumerate(zip(temperatures, temp_descriptions)):\n",
        "        print(f\"{'='*60}\")\n",
        "        print(f\"생성 #{i+1} - Temperature {temp} ({desc})\")\n",
        "        print(f\"{'='*60}\")\n",
        "        result, _ = generate_text_with_candidates(\n",
        "            model, tokenizer, input_text, max_length, device,\n",
        "            temperature=temp, verbose=(i == 0)\n",
        "        )\n",
        "        print(f\"생성 결과: '{result}'\\n\")\n",
        "    print(\"텍스트 생성 완료!\")\n",
        "\n",
        "# 다중 생성 함수 (시드 변경으로 다양한 결과)\n",
        "def run_multiple_generation(input_text, max_length=20, num_samples=5):\n",
        "    print(\"=\"*60)\n",
        "    print(\"GPT 모델 다중 텍스트 생성\")\n",
        "    print(\"=\"*60)\n",
        "    model, tokenizer = load_model('gpt_model.pth', device)\n",
        "    if model is None:\n",
        "        return\n",
        "\n",
        "    print(f\"입력 텍스트: '{input_text}'\")\n",
        "    print(f\"생성 길이: {max_length}\")\n",
        "    print(f\"생성 개수: {num_samples}\\n\")\n",
        "    results = []\n",
        "    for i in range(num_samples):\n",
        "        torch.manual_seed(42 + i * 123)\n",
        "        temp = 0.8 + (i * 0.2)\n",
        "        print(f\"{'='*50}\")\n",
        "        print(f\"생성 #{i+1} (Temperature: {temp:.1f})\")\n",
        "        print(f\"{'='*50}\")\n",
        "        result, _ = generate_text_with_candidates(\n",
        "            model, tokenizer, input_text, max_length, device,\n",
        "            temperature=temp, verbose=(i == 0)\n",
        "        )\n",
        "        results.append(result)\n",
        "        print(f\"결과 #{i+1}: '{result}'\\n\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"생성 결과 요약\")\n",
        "    print(\"=\"*60)\n",
        "    for i, result in enumerate(results, 1):\n",
        "        print(f\"{i}. '{result}'\")\n",
        "    print(\"\\n다중 텍스트 생성 완료!\")\n",
        "    return results\n",
        "\n",
        "\n",
        "# --- 메인 실행 ---\n",
        "print(\"모델 텍스트 생성\")\n",
        "print(\"=\"*60)\n",
        "print(\"1. 기본 5개 생성: run_generation('입력텍스트')\")\n",
        "print(\"2. 다중 생성 (시드 변경): run_multiple_generation('입력텍스트')\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 기본 실행 (5개 Temperature 설정으로 생성)\n",
        "run_generation(\"고기가\", max_length=20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pobmSSZRniNC",
        "outputId": "21686615-1b52-45ad-f1b0-120c5fd4563e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델 텍스트 생성\n",
            "============================================================\n",
            "1. 기본 5개 생성: run_generation('입력텍스트')\n",
            "2. 다중 생성 (시드 변경): run_multiple_generation('입력텍스트')\n",
            "============================================================\n",
            "============================================================\n",
            "위치 인코딩 정보\n",
            "============================================================\n",
            "임베딩 차원: 256\n",
            "최대 길이: 256\n",
            "PE 값 범위: [-1.000, 1.000]\n",
            "sin/cos 함수로 생성\n",
            "\n",
            "============================================================\n",
            "모델 구조\n",
            "============================================================\n",
            "모델 타입: GPT (Decoder-Only Transformer)\n",
            "어휘 크기: 54\n",
            "임베딩 차원: 256\n",
            "어텐션 헤드: 16\n",
            "디코더 층: 12\n",
            "FFN 차원: 256\n",
            "최대 시퀀스 길이: 256\n",
            "드롭아웃: 0.1\n",
            "총 파라미터: 4,777,526\n",
            "\n",
            "============================================================\n",
            "모델 로드 완료\n",
            "============================================================\n",
            "모델 타입: Decoder-Only Transformer\n",
            "어휘 크기: 54\n",
            "임베딩 차원: 256\n",
            "어텐션 헤드: 16\n",
            "디코더 층: 12\n",
            "최대 시퀀스 길이: 256\n",
            "토크나이저: KLUE/BERT\n",
            "\n",
            "입력 텍스트: '고기가'\n",
            "생성 길이: 20\n",
            "\n",
            "============================================================\n",
            "생성 #1 - Temperature 0.3 (가장 확률 높은 토큰 선택)\n",
            "============================================================\n",
            "Input text: '고기가' (Temperature: 0.3)\n",
            "Tokenized result: [1, 33, 3, 2]\n",
            "Token details: ['1:<sos>', '33:고기', '3:<unk>', '2:<eos>']\n",
            "\n",
            "============================================================\n",
            "Model Forward Pass Analysis\n",
            "============================================================\n",
            "Input shape: torch.Size([1, 4])\n",
            "Input token IDs (first sample): tensor([ 1, 33,  3,  2])\n",
            "Batch size: 1, Sequence length: 4\n",
            "\n",
            "[1. Token Embedding]\n",
            "Embedding shape: torch.Size([1, 4, 256])\n",
            "First token embedding (first 5 values): tensor([ 0.5848, -1.6111,  0.5732,  0.0364, -1.0626])\n",
            "Scaling factor: √256 = 16.000\n",
            "Scaled embedding (first 5 values): tensor([  9.3575, -25.7783,   9.1709,   0.5830, -17.0019])\n",
            "\n",
            "[2. Positional Encoding]\n",
            "After positional encoding shape: torch.Size([1, 4, 256])\n",
            "After positional encoding (first 5 values): tensor([  9.3575, -24.7783,   9.1709,   1.5830, -17.0019])\n",
            "\n",
            "[3. Causal Mask]\n",
            "Causal mask shape: torch.Size([1, 1, 4, 4])\n",
            "Causal mask sample (lower triangular matrix):\n",
            "tensor([[1., 0., 0., 0.],\n",
            "        [1., 1., 0., 0.],\n",
            "        [1., 1., 1., 0.],\n",
            "        [1., 1., 1., 1.]])\n",
            "\n",
            "[4. Decoder Blocks Processing]\n",
            "Total 12 decoder blocks to process\n",
            "\n",
            "--- Decoder Block 1 ---\n",
            "\n",
            "==================================================\n",
            "Attention Mechanism Analysis\n",
            "==================================================\n",
            "Input shape: torch.Size([1, 4, 256])\n",
            "Batch size: 1, Sequence length: 4\n",
            "Number of heads: 16, Head dimension: 16\n",
            "Q, K, V shape: torch.Size([1, 4, 256])\n",
            "Q sample (first token, first 5 values): tensor([  8.9676,   7.7862,   3.0823, -16.9813, -14.5175])\n",
            "Multi-head Q, K, V shape: torch.Size([1, 16, 4, 16])\n",
            "First head Q sample: tensor([  8.9676,   7.7862,   3.0823, -16.9813, -14.5175])\n",
            "Attention scores shape: torch.Size([1, 16, 4, 4])\n",
            "Scaling factor: 4.000\n",
            "Attention scores sample (first head, 3x3):\n",
            "tensor([[-24.0007, -87.7336, -30.9360],\n",
            "        [224.5428, -19.3929, -55.8376],\n",
            "        [ 18.6464, -25.3916,  44.5080]])\n",
            "Causal mask shape: torch.Size([1, 1, 4, 4])\n",
            "Causal mask sample (3x3):\n",
            "tensor([[1., 0., 0.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 1., 1.]])\n",
            "Masked attention scores (3x3):\n",
            "tensor([[-2.4001e+01, -1.0000e+09, -1.0000e+09],\n",
            "        [ 2.2454e+02, -1.9393e+01, -1.0000e+09],\n",
            "        [ 1.8646e+01, -2.5392e+01,  4.4508e+01]])\n",
            "Attention weights shape: torch.Size([1, 16, 4, 4])\n",
            "Attention weights sample (first head, 3x3):\n",
            "tensor([[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [5.8674e-12, 4.3955e-31, 1.0000e+00]])\n",
            "Row sums (should be 1.0): tensor([1., 1., 1.])\n",
            "Weighted value output shape: torch.Size([1, 16, 4, 16])\n",
            "First head output sample: tensor([-4.2696, -5.5636,  0.2677, 17.1824, 11.8552])\n",
            "Final attention output shape: torch.Size([1, 4, 256])\n",
            "==================================================\n",
            "\n",
            "========================================\n",
            "Feed Forward Network\n",
            "========================================\n",
            "Input shape: torch.Size([1, 4, 256])\n",
            "Output shape: torch.Size([1, 4, 256])\n",
            "========================================\n",
            "Decoder block final output: torch.Size([1, 4, 256])\n",
            "==================================================\n",
            "Block 1 residual effect (change amount): 12.8020\n",
            "\n",
            "--- Decoder Block 2 ---\n",
            "Block 2 residual effect (change amount): 0.2509\n",
            "\n",
            "--- Decoder Block 3 ---\n",
            "Block 3 residual effect (change amount): 0.2805\n",
            "\n",
            "--- Decoder Block 4 ---\n",
            "Block 4 residual effect (change amount): 0.2928\n",
            "\n",
            "--- Decoder Block 5 ---\n",
            "Block 5 residual effect (change amount): 0.2652\n",
            "\n",
            "--- Decoder Block 6 ---\n",
            "Block 6 residual effect (change amount): 0.2736\n",
            "\n",
            "--- Decoder Block 7 ---\n",
            "Block 7 residual effect (change amount): 0.3035\n",
            "\n",
            "--- Decoder Block 8 ---\n",
            "Block 8 residual effect (change amount): 0.2758\n",
            "\n",
            "--- Decoder Block 9 ---\n",
            "Block 9 residual effect (change amount): 0.2999\n",
            "\n",
            "--- Decoder Block 10 ---\n",
            "Block 10 residual effect (change amount): 0.2882\n",
            "\n",
            "--- Decoder Block 11 ---\n",
            "Block 11 residual effect (change amount): 0.3011\n",
            "\n",
            "--- Decoder Block 12 ---\n",
            "Block 12 residual effect (change amount): 0.2967\n",
            "\n",
            "[5. Final Output]\n",
            "After layer norm (first 5 values): tensor([ 1.4339,  0.4773, -0.1832, -1.2016, -1.8512])\n",
            "Final logits shape: torch.Size([1, 4, 54])\n",
            "Last token logits range: [-1.793, 5.759]\n",
            "============================================================\n",
            "\n",
            "--- Generation Step 1 ---\n",
            "Current text: '고기'\n",
            "Next token candidates:\n",
            "  1. '그' → '고기 그' (prob: 0.9999) ★\n",
            "  2. '멕시코' → '고기 멕시코' (prob: 0.0001)\n",
            "  3. '##는' → '고기는' (prob: 0.0000)\n",
            "  4. '40' → '고기 40' (prob: 0.0000)\n",
            "  5. '조각' → '고기 조각' (prob: 0.0000)\n",
            "\n",
            "--- Generation Step 2 ---\n",
            "Current text: '고기 그'\n",
            "Next token candidates:\n",
            "  1. '##는' → '고기 그는' (prob: 1.0000) ★\n",
            "  2. '그' → '고기 그 그' (prob: 0.0000)\n",
            "  3. '낚' → '고기 그 낚' (prob: 0.0000)\n",
            "  4. '멕시코' → '고기 그 멕시코' (prob: 0.0000)\n",
            "  5. '.' → '고기 그.' (prob: 0.0000)\n",
            "\n",
            "--- Generation Step 3 ---\n",
            "Current text: '고기 그는'\n",
            "Next token candidates:\n",
            "  1. '멕시코' → '고기 그는 멕시코' (prob: 1.0000) ★\n",
            "  2. '노인' → '고기 그는 노인' (prob: 0.0000)\n",
            "  3. '그' → '고기 그는 그' (prob: 0.0000)\n",
            "  4. '##월' → '고기 그는월' (prob: 0.0000)\n",
            "  5. '##만' → '고기 그는만' (prob: 0.0000)\n",
            "\n",
            "--- Generation Step 4 ---\n",
            "Current text: '고기 그는 멕시코'\n",
            "Next token candidates:\n",
            "  1. '만' → '고기 그는 멕시코 만' (prob: 1.0000) ★\n",
            "  2. '그' → '고기 그는 멕시코 그' (prob: 0.0000)\n",
            "  3. '혼자' → '고기 그는 멕시코 혼자' (prob: 0.0000)\n",
            "  4. '##를' → '고기 그는 멕시코를' (prob: 0.0000)\n",
            "  5. '대부분' → '고기 그는 멕시코 대부분' (prob: 0.0000)\n",
            "\n",
            "--- Generation Step 5 ---\n",
            "Current text: '고기 그는 멕시코 만'\n",
            "Next token candidates:\n",
            "  1. '##에서' → '고기 그는 멕시코 만에서' (prob: 1.0000) ★\n",
            "  2. '그' → '고기 그는 멕시코 만 그' (prob: 0.0000)\n",
            "  3. '멕시코' → '고기 그는 멕시코 만 멕시코' (prob: 0.0000)\n",
            "  4. '40' → '고기 그는 멕시코 만 40' (prob: 0.0000)\n",
            "  5. '##은' → '고기 그는 멕시코 만은' (prob: 0.0000)\n",
            "생성 결과: '고기 그는 멕시코 만에서 조각배를 타고 고기잡이를 하는 노인이었다. 대부분'\n",
            "\n",
            "============================================================\n",
            "생성 #2 - Temperature 0.7 (안정적인 토큰 생성)\n",
            "============================================================\n",
            "생성 결과: '고기 그는 멕시코 만에서 조각배를 타고 고기잡이를 하는 노인이었다. 대부분'\n",
            "\n",
            "============================================================\n",
            "생성 #3 - Temperature 1.0 (균형잡힌 토큰 생성)\n",
            "============================================================\n",
            "생성 결과: '고기 그는 멕시코 만에서 조각배를 타고 고기잡이를 하는 노인이었다. 대부분'\n",
            "\n",
            "============================================================\n",
            "생성 #4 - Temperature 1.3 (창의적 (다양한 표현))\n",
            "============================================================\n",
            "생성 결과: '고기 멕시코일 그는 노인 그는 멕시코 만에서 조각 낚지 못하고 허송세월만'\n",
            "\n",
            "============================================================\n",
            "생성 #5 - Temperature 1.7 (매우 창의적 (실험적 생성))\n",
            "============================================================\n",
            "생성 결과: '고기는 노인이 지 멕시코 멕시코 만에서은 혼자 처음 고기 타고 고기송송'\n",
            "\n",
            "텍스트 생성 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H99XQWmXtjFc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}